#!/bin/bash
#SBATCH --job-name=fred_multi # nom du job
#SBATCH -C v100-32g # reserver des GPU 32 Go seulement
#SBATCH --qos=qos_gpu-dev # QoS
#SBATCH --output=fred_multi%j.out # fichier de sortie (%j = job ID)
#SBATCH --error=fred_multi%j.err # fichier d’erreur (%j = job ID)
#SBATCH --time=00:20:00 # temps maximal d’allocation "(HH:MM:SS)"
#SBATCH --nodes=1 # reserver 1 nœud
#SBATCH --ntasks=4 # reserver 4 taches (ou processus MPI)
#SBATCH --gres=gpu:4 # reserver 4 GPU
#SBATCH --cpus-per-task=10 # reserver 4 CPU par tache (et memoire associee)
#SBATCH --hint=nomultithread # desactiver l’hyperthreading

module purge # nettoyer les modules herites par defaut
conda deactivate # desactiver les environnements herites par defaut
module load tensorflow-gpu/py3/2.3.1 # charger les modules
set -x # activer l’echo des commandes
srun python -u train_fred_multigpu.py # executer son script
